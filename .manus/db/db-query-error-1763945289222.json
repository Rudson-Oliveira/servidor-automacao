{
  "query": "INSERT INTO skills (\n  id,\n  nome,\n  descricao,\n  instrucoes,\n  exemplo,\n  tags,\n  categoria,\n  autonomiaNivel\n) VALUES (\n  330002,\n  'Consultar Perplexity AI',\n  'Realizar pesquisas e consultas usando Perplexity AI, uma IA de busca que fornece respostas contextualizadas com fontes verificadas e citações acadêmicas.',\n  'Endpoint: POST /api/trpc/perplexity.consultar\n\nParâmetros obrigatórios:\n- query: string - Pergunta ou consulta a ser feita\n- apiKey: string - API key do Perplexity (formato: pplx-xxxxxxxxxxxxxxxxxxxxx)\n\nParâmetros opcionais:\n- model: string - Modelo a usar (padrão: llama-3.1-sonar-small-128k-online)\n  Opções: llama-3.1-sonar-small-128k-online, llama-3.1-sonar-large-128k-online, llama-3.1-sonar-huge-128k-online\n- temperature: number - Temperatura (0-2, padrão: 0.2)\n- maxTokens: number - Máximo de tokens (1-4000, padrão: 1000)\n\nFormato do payload (tRPC):\n{\n  \"json\": {\n    \"query\": \"Sua pergunta aqui\",\n    \"apiKey\": \"pplx-xxxxxxxxxxxxxxxxxxxxx\",\n    \"model\": \"llama-3.1-sonar-large-128k-online\",\n    \"temperature\": 0.2,\n    \"maxTokens\": 2000\n  }\n}\n\nResposta esperada:\n{\n  \"result\": {\n    \"data\": {\n      \"json\": {\n        \"sucesso\": true,\n        \"resposta\": \"Texto da resposta...\",\n        \"citacoes\": [\"url1\", \"url2\"],\n        \"metadata\": {\n          \"modelo\": \"llama-3.1-sonar-large-128k-online\",\n          \"tokensUsados\": 1250,\n          \"temperature\": 0.2,\n          \"timestamp\": \"2025-11-23T20:00:00.000Z\"\n        }\n      }\n    }\n  }\n}\n\nBoas práticas:\n1. Seja específico nas perguntas\n2. Use modelo small para consultas rápidas, large para pesquisas complexas\n3. Temperature baixa (0.1-0.2) para respostas factuais\n4. Sempre verifique as citações retornadas\n5. Use maxTokens apropriado para o tipo de resposta esperada',\n  '{\n  \"query\": \"Quais são as últimas descobertas sobre inteligência artificial em 2025?\",\n  \"apiKey\": \"pplx-xxxxxxxxxxxxxxxxxxxxx\",\n  \"model\": \"llama-3.1-sonar-large-128k-online\",\n  \"temperature\": 0.2,\n  \"maxTokens\": 2000\n}',\n  'perplexity,pesquisa,busca,citacoes,fontes,ia,llm,online',\n  'pesquisa',\n  'total'\n) ON DUPLICATE KEY UPDATE\n  descricao = VALUES(descricao),\n  instrucoes = VALUES(instrucoes),\n  exemplo = VALUES(exemplo),\n  tags = VALUES(tags),\n  categoria = VALUES(categoria),\n  autonomiaNivel = VALUES(autonomiaNivel)",
  "command": "mysql --batch --raw --column-names --default-character-set=utf8mb4 --host gateway02.us-east-1.prod.aws.tidbcloud.com --port 4000 --user 46yA7HaDwBP5MYq.c5fbe4e16cff --database ALEjofy2PjgFnShwZRqCD7 --execute INSERT INTO skills (\n  id,\n  nome,\n  descricao,\n  instrucoes,\n  exemplo,\n  tags,\n  categoria,\n  autonomiaNivel\n) VALUES (\n  330002,\n  'Consultar Perplexity AI',\n  'Realizar pesquisas e consultas usando Perplexity AI, uma IA de busca que fornece respostas contextualizadas com fontes verificadas e citações acadêmicas.',\n  'Endpoint: POST /api/trpc/perplexity.consultar\n\nParâmetros obrigatórios:\n- query: string - Pergunta ou consulta a ser feita\n- apiKey: string - API key do Perplexity (formato: pplx-xxxxxxxxxxxxxxxxxxxxx)\n\nParâmetros opcionais:\n- model: string - Modelo a usar (padrão: llama-3.1-sonar-small-128k-online)\n  Opções: llama-3.1-sonar-small-128k-online, llama-3.1-sonar-large-128k-online, llama-3.1-sonar-huge-128k-online\n- temperature: number - Temperatura (0-2, padrão: 0.2)\n- maxTokens: number - Máximo de tokens (1-4000, padrão: 1000)\n\nFormato do payload (tRPC):\n{\n  \"json\": {\n    \"query\": \"Sua pergunta aqui\",\n    \"apiKey\": \"pplx-xxxxxxxxxxxxxxxxxxxxx\",\n    \"model\": \"llama-3.1-sonar-large-128k-online\",\n    \"temperature\": 0.2,\n    \"maxTokens\": 2000\n  }\n}\n\nResposta esperada:\n{\n  \"result\": {\n    \"data\": {\n      \"json\": {\n        \"sucesso\": true,\n        \"resposta\": \"Texto da resposta...\",\n        \"citacoes\": [\"url1\", \"url2\"],\n        \"metadata\": {\n          \"modelo\": \"llama-3.1-sonar-large-128k-online\",\n          \"tokensUsados\": 1250,\n          \"temperature\": 0.2,\n          \"timestamp\": \"2025-11-23T20:00:00.000Z\"\n        }\n      }\n    }\n  }\n}\n\nBoas práticas:\n1. Seja específico nas perguntas\n2. Use modelo small para consultas rápidas, large para pesquisas complexas\n3. Temperature baixa (0.1-0.2) para respostas factuais\n4. Sempre verifique as citações retornadas\n5. Use maxTokens apropriado para o tipo de resposta esperada',\n  '{\n  \"query\": \"Quais são as últimas descobertas sobre inteligência artificial em 2025?\",\n  \"apiKey\": \"pplx-xxxxxxxxxxxxxxxxxxxxx\",\n  \"model\": \"llama-3.1-sonar-large-128k-online\",\n  \"temperature\": 0.2,\n  \"maxTokens\": 2000\n}',\n  'perplexity,pesquisa,busca,citacoes,fontes,ia,llm,online',\n  'pesquisa',\n  'total'\n) ON DUPLICATE KEY UPDATE\n  descricao = VALUES(descricao),\n  instrucoes = VALUES(instrucoes),\n  exemplo = VALUES(exemplo),\n  tags = VALUES(tags),\n  categoria = VALUES(categoria),\n  autonomiaNivel = VALUES(autonomiaNivel)",
  "returncode": 1,
  "logs": [
    "ERROR 1054 (42S22) at line 1: Unknown column 'autonomiaNivel' in 'field list'"
  ]
}